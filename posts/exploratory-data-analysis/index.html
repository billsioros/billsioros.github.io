<!doctype html><html><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta http-equiv=Accept-CH content="DPR, Viewport-Width, Width"><link rel=icon href=/fav.png type=image/gif><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><link rel=stylesheet href=/css/font.css media=all><meta property="og:url" content="https://billsioros.github.io/posts/exploratory-data-analysis/"><meta property="og:site_name" content="Vassilis Sioros | Software / Machine Learning Engineer"><meta property="og:title" content="Exploratory Data Analysis"><meta property="og:description" content="Decoding Heart Health with Data Insights!"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-06T00:00:00+00:00"><meta property="article:tag" content="Python"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Data Science"><meta property="article:tag" content="Artificial Intelligence"><meta property="article:tag" content="Exploratory Data Analysis"><meta name=twitter:card content="summary"><meta name=twitter:title content="Exploratory Data Analysis"><meta name=twitter:description content="Decoding Heart Health with Data Insights!"><link rel=stylesheet href=/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=/css/header.css media=all><link rel=stylesheet href=/css/footer.css media=all><link rel=stylesheet href=/css/theme.css media=all><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--brand-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#007bff;--brand-color-dark:#ffffff;--secondary-color-dark:#212529}body{min-height:100%;display:flex;flex-direction:column;font-size:1rem;font-weight:400;line-height:1.5;text-align:left}html{height:100%;background-color:var(--background-color)!important}body::-webkit-scrollbar{height:0;width:8px;background-color:var(--background-color)}::-webkit-scrollbar-track{border-radius:1rem}::-webkit-scrollbar-thumb{border-radius:1rem;background:#b0b0b0;outline:1px solid var(--background-color)}#search-content::-webkit-scrollbar{width:.5em;height:.1em;background-color:var(--background-color)}</style><meta name=description content="Decoding Heart Health with Data Insights!"><meta name=author content="Vassilis Sioros"><meta property="og:image" content="https://billsioros.github.io/images/posts/exploratory-data-analysis/index.png"><link rel=stylesheet href=/css/single.css><script defer src=/fontawesome-6/all-6.4.2.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.25.0/tocbot.css><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.25.0/tocbot.min.js></script><title>Exploratory Data Analysis | Vassilis Sioros | Software / Machine Learning Engineer</title></head><body class=light><script>let localStorageValue=localStorage.getItem("pref-theme"),mediaQuery=window.matchMedia("(prefers-color-scheme: dark)").matches;switch(localStorageValue){case"dark":document.body.classList.add("dark");break;case"light":document.body.classList.remove("dark");break;default:mediaQuery&&document.body.classList.add("dark");break}</script><script>var prevScrollPos=window.pageYOffset;window.addEventListener("scroll",function(){let s=document.getElementById("profileHeader"),t=window.pageYOffset,n=!1,o=!1,i=o?prevScrollPos>t:t>0;i?s.classList.add("showHeaderOnTop"):n=!0,t===0&&(n=!0),n&&s.classList.remove("showHeaderOnTop"),prevScrollPos=t})</script><header id=profileHeader><nav class="pb-2 navbar navbar-expand-lg animate"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.png width=30 height=30 class="d-inline-block align-top">
Vassilis Sioros</a><div class="d-flex justify-content-end" style=flex-grow:1><button id=theme-toggle type=checkbox></button></div><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" style=flex-grow:0!important id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text"><a class=nav-link href=/#experience aria-label=experience>Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Projects</a></li><li class="nav-item navbar-text"><a class=nav-link href=/posts title="Blog posts">Blog</a></li></ul></div></div></nav></header><div id=content><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class="title mb-5"><h1 class="text-center mb-4">Exploratory Data Analysis</h1><h6 class="text-center mb-4">Decoding Heart Health with Data Insights!</h6><div class=text-center>Aug 6, 2024
<span id=readingTime>min read
</span><small>| </small><a target=_blank href=https://colab.research.google.com/github/billsioros/billsioros.github.io/blob/master/static/code/exploratory-data-analysis.ipynb><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></div></div><div class=featured-image><img class="img-fluid mx-auto d-block" src=/images/posts/exploratory-data-analysis/index.png alt="Exploratory Data Analysis"></div><article class="page-content toc-content p-2"><p>Exploratory Data Analysis (EDA) is like being a detective at a party full of numbers. Let&rsquo;s take the <a href=https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction>Heart Disease Prediction Dataset</a> as an example.</p><p>Imagine you walk into this party, and instead of guests, there are columns of data: ages, blood pressures, cholesterol levels, and so on. Your job as the detective is to mingle with these numbers, get to know them, and uncover their secrets.</p><p>You start by looking around to see who&rsquo;s who. You might notice that the average age of the guests is around 50. Maybe you spot some interesting patterns, like how those with high cholesterol tend to hang out in one corner. You create some cool charts and graphs, which are like taking snapshots of the party. These visuals help you see at a glance who the outliers are‚Äîthe really tall guy in the middle of a crowd of short folks, or the person who&rsquo;s overdressed for the occasion.</p><p>Occasionally, you overhear intriguing snippets of conversation. For instance, you might hear that smokers are whispering about high blood pressure more than non-smokers. This eavesdropping (or correlation) helps you understand how different variables might be related.</p><p>EDA is all about getting a feel for the data without making any big assumptions or trying to prove anything just yet. It&rsquo;s like being a curious guest at a party, asking questions, spotting trends, and taking notes, all to get a clearer picture of what‚Äôs really going on.</p><h2 id=dataset-overview>Dataset Overview</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>Path</span><span class=o>.</span><span class=n>cwd</span><span class=p>()</span> <span class=o>/</span> <span class=s2>&#34;heart.csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>info</span><span class=p>()</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>&lt;class <span class=s1>&#39;pandas.core.frame.DataFrame&#39;</span>&gt;
</span></span><span class=line><span class=cl>RangeIndex: <span class=m>918</span> entries, <span class=m>0</span> to <span class=m>917</span>
</span></span><span class=line><span class=cl>Data columns <span class=o>(</span>total <span class=m>12</span> columns<span class=o>)</span>:
</span></span><span class=line><span class=cl> <span class=c1>#   Column          Non-Null Count  Dtype</span>
</span></span><span class=line><span class=cl>---  ------          --------------  -----
</span></span><span class=line><span class=cl> <span class=m>0</span>   Age             <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl> <span class=m>1</span>   Sex             <span class=m>918</span> non-null    object
</span></span><span class=line><span class=cl> <span class=m>2</span>   ChestPain       <span class=m>918</span> non-null    object
</span></span><span class=line><span class=cl> <span class=m>3</span>   RestingBP       <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl> <span class=m>4</span>   Cholesterol     <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl> <span class=m>5</span>   FastingBS       <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl> <span class=m>6</span>   RestingECG      <span class=m>918</span> non-null    object
</span></span><span class=line><span class=cl> <span class=m>7</span>   MaxHR           <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl> <span class=m>8</span>   ExerciseAngina  <span class=m>918</span> non-null    object
</span></span><span class=line><span class=cl> <span class=m>9</span>   Oldpeak         <span class=m>918</span> non-null    float64
</span></span><span class=line><span class=cl> <span class=m>10</span>  ST_Slope        <span class=m>918</span> non-null    object
</span></span><span class=line><span class=cl> <span class=m>11</span>  HeartDisease    <span class=m>918</span> non-null    int64
</span></span><span class=line><span class=cl>dtypes: float64<span class=o>(</span>1<span class=o>)</span>, int64<span class=o>(</span>6<span class=o>)</span>, object<span class=o>(</span>5<span class=o>)</span>
</span></span><span class=line><span class=cl>memory usage: 86.2+ KB
</span></span></code></pre></div><p>A brief explanation of each column (taken directly from the <a href=https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction>Heart Disease Prediction Dataset</a> üòù) is given below:</p><ul><li><strong>Age</strong>: age of the patient [years]</li><li><strong>Sex</strong>: sex of the patient [M: Male, F: Female]</li><li><strong>ChestPainType</strong>: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]</li><li><strong>RestingBP</strong>: resting blood pressure [mm Hg]</li><li><strong>Cholesterol</strong>: serum cholesterol [mm/dl]</li><li><strong>FastingBS</strong>: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]</li><li><strong>RestingECG</strong>: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes&rsquo; criteria]</li><li><strong>MaxHR</strong>: maximum heart rate achieved [Numeric value between 60 and 202]</li><li><strong>ExerciseAngina</strong>: exercise-induced angina [Y: Yes, N: No]</li><li><strong>Oldpeak</strong>: oldpeak = ST [Numeric value measured in depression]</li><li><strong>ST_Slope</strong>: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]</li><li><strong>HeartDisease</strong>: output class [1: heart disease, 0: Normal]</li></ul><p>As we can see, the dataset contains 918 samples, each characterized by 11 distinct features. The features <code>Sex</code>, <code>ChestPain</code>, <code>FastingBS</code>, <code>RestingECG</code>, <code>ExerciseAngina</code>, and <code>ST_Slope</code> are categorical. We‚Äôll use <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html><code>LabelEncoder</code></a> to convert these into numerical values. We‚Äôll create a separate encoder for each feature and store them in a dictionary for future use.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>target_variable</span> <span class=o>=</span> <span class=s2>&#34;HeartDisease&#34;</span>
</span></span><span class=line><span class=cl><span class=n>categorical_features</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;Sex&#34;</span><span class=p>,</span> <span class=s2>&#34;ChestPain&#34;</span><span class=p>,</span> <span class=s2>&#34;FastingBS&#34;</span><span class=p>,</span> <span class=s2>&#34;RestingECG&#34;</span><span class=p>,</span> <span class=s2>&#34;ExerciseAngina&#34;</span><span class=p>,</span> <span class=s2>&#34;ST_Slope&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>numerical_features</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=p>)</span><span class=o>.</span><span class=n>difference</span><span class=p>([</span><span class=n>target_variable</span><span class=p>,</span> <span class=o>*</span><span class=n>categorical_features</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>encoders</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>column</span> <span class=ow>in</span> <span class=n>categorical_features</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>encoder</span> <span class=o>=</span> <span class=n>LabelEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=n>encoder</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=n>column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>encoders</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=n>encoder</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>information</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>describe</span><span class=p>()</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl><span class=n>missing</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>isna</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=s2>&#34;Missing Values&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>unique</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>nunique</span><span class=p>()</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=s2>&#34;Unique Values&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>information</span><span class=p>,</span> <span class=n>missing</span><span class=p>,</span> <span class=n>unique</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><table><thead><tr><th></th><th>count</th><th>mean</th><th>std</th><th>min</th><th>25%</th><th>50%</th><th>75%</th><th>max</th><th>Missing Values</th><th>Unique Values</th></tr></thead><tbody><tr><td>Age</td><td>918.0</td><td>53.510893</td><td>9.432617</td><td>28.0</td><td>47.00</td><td>54.0</td><td>60.0</td><td>77.0</td><td>0</td><td>50</td></tr><tr><td>Sex</td><td>918.0</td><td>0.789760</td><td>0.407701</td><td>0.0</td><td>1.00</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0</td><td>2</td></tr><tr><td>ChestPain</td><td>918.0</td><td>0.781046</td><td>0.956519</td><td>0.0</td><td>0.00</td><td>0.0</td><td>2.0</td><td>3.0</td><td>0</td><td>4</td></tr><tr><td>RestingBP</td><td>918.0</td><td>132.396514</td><td>18.514154</td><td>0.0</td><td>120.00</td><td>130.0</td><td>140.0</td><td>200.0</td><td>0</td><td>67</td></tr><tr><td>Cholesterol</td><td>918.0</td><td>198.799564</td><td>109.384145</td><td>0.0</td><td>173.25</td><td>223.0</td><td>267.0</td><td>603.0</td><td>0</td><td>222</td></tr><tr><td>FastingBS</td><td>918.0</td><td>0.233115</td><td>0.423046</td><td>0.0</td><td>0.00</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>2</td></tr><tr><td>RestingECG</td><td>918.0</td><td>0.989107</td><td>0.631671</td><td>0.0</td><td>1.00</td><td>1.0</td><td>1.0</td><td>2.0</td><td>0</td><td>3</td></tr><tr><td>MaxHR</td><td>918.0</td><td>136.809368</td><td>25.460334</td><td>60.0</td><td>120.00</td><td>138.0</td><td>156.0</td><td>202.0</td><td>0</td><td>119</td></tr><tr><td>ExerciseAngina</td><td>918.0</td><td>0.404139</td><td>0.490992</td><td>0.0</td><td>0.00</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0</td><td>2</td></tr><tr><td>Oldpeak</td><td>918.0</td><td>0.887364</td><td>1.066570</td><td>-2.6</td><td>0.00</td><td>0.6</td><td>1.5</td><td>6.2</td><td>0</td><td>53</td></tr><tr><td>ST_Slope</td><td>918.0</td><td>1.361656</td><td>0.607056</td><td>0.0</td><td>1.00</td><td>1.0</td><td>2.0</td><td>2.0</td><td>0</td><td>3</td></tr><tr><td>HeartDisease</td><td>918.0</td><td>0.553377</td><td>0.497414</td><td>0.0</td><td>0.00</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0</td><td>2</td></tr></tbody></table><p>At first impression, we can see that:</p><ul><li>Fortunately, the dataset contains no missing values, so there is no need for imputation or deletion of rows.</li><li>All features exhibit a relatively high standard deviation, suggesting that low variance elimination methods like <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html><code>VarianceThreshold</code></a> may not be suitable.</li><li>The value ranges of individual feature distributions vary significantly. We need to examine each feature to determine if it follows a normal distribution and to identify any outliers.</li></ul><h2 id=dataset-balance>Dataset Balance</h2><p>As shown below the dataset is relatively balanced. If that wasn&rsquo;t the case, we might had to employ an oversampling technique, such as <a href=https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html><code>SMOTE</code></a>.</p><p><img src=/images/posts/exploratory-data-analysis/balance.png alt="Dataset Class Balance"></p><h2 id=feature-distribution--outliers>Feature Distribution & Outliers</h2><p>To effectively train our model, it&rsquo;s crucial to analyze the distribution of each feature and identify any outliers. Based on these findings, we can decide whether to use <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html><code>StandardScaler</code></a> or <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html><code>RobustScaler</code></a> to normalize the features appropriately. The <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html><code>MinMaxScaler</code></a> might be worth considering if the features are not Gaussian. However, it is probably not the most suitable option since it assumes features are bounded within a specific range, which is not the case.</p><p>We know that categorical variables are inherently non-continuous and thus cannot follow a normal distribution. However, we can assess the distribution of continuous features to determine if they approximate a normal distribution.</p><p>Furthermore, the concept of outliers in categorical data is somewhat problematic. To identify an outlier, there needs to be a measure of difference between data. Taking this into consideration, we will exclude categorical features from our outlier detection process.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>num_features</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>num_cols</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>num_rows</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_features</span> <span class=o>//</span> <span class=n>num_cols</span><span class=p>)</span> <span class=o>+</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_features</span> <span class=o>%</span> <span class=n>num_cols</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_cols</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span> <span class=o>*</span> <span class=n>num_rows</span><span class=p>),</span> <span class=n>constrained_layout</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span> <span class=o>=</span> <span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>feature</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>sns</span><span class=o>.</span><span class=n>histplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=n>feature</span><span class=p>,</span> <span class=n>kde</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>stat</span><span class=o>=</span><span class=s2>&#34;density&#34;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=n>feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=o>.</span><span class=n>delaxes</span><span class=p>(</span><span class=n>axes</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><img src=/images/posts/exploratory-data-analysis/num_distribution.png alt="The Distributions of Numerical Features"></p><p>Based on our analysis, we can draw the following conclusions:</p><ul><li><strong>Age</strong> and <strong>MaxHR</strong> appear to follow a normal distribution.</li><li><strong>Oldpeak</strong> is right-skewed.</li><li><strong>Cholesterol</strong> exhibits a bimodal distribution.</li><li><strong>RestingBP</strong> might follow a normal distribution, but its high variability prevents us from determining this with certainty.</li></ul><p>It is evident that the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html><code>StandardScaler</code></a> is probably not be suitable in this case.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>num_features</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>num_cols</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>num_rows</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_features</span> <span class=o>//</span> <span class=n>num_cols</span><span class=p>)</span> <span class=o>+</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_features</span> <span class=o>%</span> <span class=n>num_cols</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_cols</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span> <span class=o>*</span> <span class=n>num_rows</span><span class=p>),</span> <span class=n>constrained_layout</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span> <span class=o>=</span> <span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>feature</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>sns</span><span class=o>.</span><span class=n>boxplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>feature</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s2>&#34;HeartDisease&#34;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>gap</span><span class=o>=</span><span class=mf>.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=n>feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=o>.</span><span class=n>delaxes</span><span class=p>(</span><span class=n>axes</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><img src=/images/posts/exploratory-data-analysis/num_outliers.png alt="Outliers in Numerical Features"></p><p>It is evident that all features, exhibit at least some outliers. Consequently, we will apply the <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html><code>RobustScaler</code></a> for feature normalization to address these outliers effectively.</p><h2 id=correlation-analysis>Correlation Analysis</h2><p>We now analyze the correlation between different features and our target variable, as well as examine the relationships among the features themselves, to gain deeper insights.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>num_features</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>categorical_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>num_cols</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>num_rows</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_features</span> <span class=o>//</span> <span class=n>num_cols</span><span class=p>)</span> <span class=o>+</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_features</span> <span class=o>%</span> <span class=n>num_cols</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_cols</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span> <span class=o>*</span> <span class=n>num_rows</span><span class=p>),</span> <span class=n>constrained_layout</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span> <span class=o>=</span> <span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>feature</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>categorical_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>sns</span><span class=o>.</span><span class=n>countplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=n>feature</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s2>&#34;HeartDisease&#34;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=n>feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=o>.</span><span class=n>delaxes</span><span class=p>(</span><span class=n>axes</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><img src=/images/posts/exploratory-data-analysis/cat_correlation.png alt="Correlation of Categorical Features with the Target Variable"></p><p>We can see that:</p><ul><li>Male patients are more prone to heart disease compared to female patients.</li><li>Asymptomatic chest pain <code>ASY (0)</code> is highly indicative of heart disease, while typical angina <code>TA (3)</code> seems to have minimal effect on outcomes. In contrast, atypical angina <code>ATA (1)</code> and non-anginal pain <code>NAP (2)</code> seem to be negatively correlated with heart disease.</li><li>A fasting blood sugar greater than 120 mg/dl <code>(FastingBS = 1)</code> is linked to a higher likelihood of heart disease. On the other hand, a fasting blood sugar less than 120 mg/dl <code>(FastingBS = 0)</code> is only marginally associated with a lower likelihood of heart disease.</li><li><code>RestingECG</code> does not appear to influence the likelihood of heart disease.</li><li>Exercise-induced angina <code>(ExerciseAngina = 1)</code> is strongly associated with heart disease, while its absence is strongly correlated with a lower likelihood of the condition.</li><li>A downward <code>ST_Slope</code> shows a slight correlation with heart disease, a flat <code>ST_Slope</code> is strongly correlated, and an upward <code>ST_Slope</code> is associated with a lower likelihood of heart disease.</li></ul><blockquote><p><code>RestingECG</code> could be considered insignificant and will most probably be dropped from the dataset.</p></blockquote><p>We also observe that for some categorical features, certain values are predictive of heart disease, while others show no correlation with the condition (as in the case of <code>FastingBS</code>). To address this, we could apply <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html><code>OneHotEncoder</code></a>. This technique converts categorical values into binary features, enabling the model to better interpret the presence or absence of specific categories and potentially enhancing predictive accuracy. Additionally, one-hot encoding prevents the algorithm from mistakenly assuming an ordinal relationship among the categories.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>num_features</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>num_cols</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>num_rows</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_features</span> <span class=o>//</span> <span class=n>num_cols</span><span class=p>)</span> <span class=o>+</span> <span class=nb>int</span><span class=p>(</span><span class=n>num_features</span> <span class=o>%</span> <span class=n>num_cols</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_cols</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span> <span class=o>*</span> <span class=n>num_rows</span><span class=p>),</span> <span class=n>constrained_layout</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>axes</span> <span class=o>=</span> <span class=n>axes</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>feature</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>numerical_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>sns</span><span class=o>.</span><span class=n>histplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=n>feature</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s2>&#34;HeartDisease&#34;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=n>feature</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>axes</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=o>.</span><span class=n>delaxes</span><span class=p>(</span><span class=n>axes</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><img src=/images/posts/exploratory-data-analysis/num_correlation.png alt="Correlation of Numerical Features with the Target Variable"></p><p>It&rsquo;s clear that:</p><ul><li><code>Age</code> shows a strong correlation with heart disease, with older individuals being more likely to develop the condition.</li><li><code>Resting Blood Pressure (RestingBP)</code> is inversely related to heart disease risk with lower levels being associated with a reduced likelihood of heart disease.</li><li><code>Cholesterol levels</code> present a complex relationship with heart disease: both very low and very high cholesterol values are strongly correlated with an increased risk.</li><li><code>Maximum Heart Rate (MaxHR)</code> has a negative correlation with heart disease, meaning higher values are associated with a lower risk.</li><li>Lower <code>Oldpeak</code> values are generally associated with a reduced likelihood of heart disease. However, there is some overlap at very low values, which can make interpretation more challenging.</li></ul><blockquote><p><code>RestingBP</code> may be omitted if further analysis deems it unimportant.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>corr</span><span class=p>(),</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;coolwarm&#39;</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;.2f&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p><img src=/images/posts/exploratory-data-analysis/confusion_matrix.png alt="Correlation Matrix of Features and Target Variable"></p><ul><li>The correlation matrix reveals a strong correlation between certain features, such as <code>ST_Slope</code> and <code>Oldpeak</code>. This high correlation can adversely affect the model&rsquo;s performance. To mitigate this issue, we need to consider strategies to address multicollinearity. Options include dropping one of the correlated features, combining them into a single variable, or selecting a model that is inherently resistant to multicollinearity, such as a <a href=https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html><code>DecisionTreeClassifier</code></a>.</li><li>We could also use <a href=https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html>Principal Component Analysis (PCA)</a> to tackle the issue of multicollinearity, by transforming the original variables into a new set of uncorrelated variables. However, PCA assumes the data is normally distributed, which is not the case here.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>corr</span><span class=p>()</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s1>&#39;HeartDisease&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>nlargest</span><span class=p>(</span><span class=mi>11</span><span class=p>,</span> <span class=s1>&#39;HeartDisease&#39;</span><span class=p>)[</span><span class=s1>&#39;HeartDisease&#39;</span><span class=p>]</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>ST_Slope          0.558771
</span></span><span class=line><span class=cl>ExerciseAngina    0.494282
</span></span><span class=line><span class=cl>Oldpeak           0.403951
</span></span><span class=line><span class=cl>MaxHR             0.400421
</span></span><span class=line><span class=cl>ChestPain         0.386828
</span></span><span class=line><span class=cl>Sex               0.305445
</span></span><span class=line><span class=cl>Age               0.282039
</span></span><span class=line><span class=cl>FastingBS         0.267291
</span></span><span class=line><span class=cl>Cholesterol       0.232741
</span></span><span class=line><span class=cl>RestingBP         0.107589
</span></span><span class=line><span class=cl>RestingECG        0.057384
</span></span><span class=line><span class=cl>Name: HeartDisease, dtype: float64
</span></span></code></pre></div><p>Our findings are consistent with our previous statements. The data indicates that <code>RestingECG</code> is the feature least correlated with <code>HeartDisease</code>, followed by <code>RestingBP</code>. Additionally, <code>Cholesterol</code> shows a weak correlation with <code>HeartDisease</code>. Notably, the correlation coefficients for these features are all below <strong>0.15</strong>. As a result, we will be removing these three features.</p><h2 id=conclusions>Conclusions</h2><ul><li>The dataset is balanced and contains no missing values, eliminating the need for imputation, row deletion, or oversampling.</li><li>We conclude that <code>RestingECG</code>, <code>RestingBP</code>, and <code>Cholesterol</code> are not indicative of heart disease and will therefore be excluded from the dataset.</li><li>We will <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html>OneHotEncoder</a> to encode our categorical features.</li><li>Numerical features are not normally distributed and contain outliers. To address this we will employ <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html>RobustScaler</a>.</li><li>We will only consider models that are robust to multicollinearity.</li></ul><p><em>We reverse the encoding of our categorical features to preserve the original values, drop the aforementioned features, and save the preprocessed dataset.</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>column</span> <span class=ow>in</span> <span class=n>categorical_features</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>column</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span><span class=p>[</span><span class=n>column</span><span class=p>]</span> <span class=o>=</span> <span class=n>encoders</span><span class=p>[</span><span class=n>column</span><span class=p>]</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=n>column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;RestingECG&#34;</span><span class=p>,</span> <span class=s2>&#34;RestingBP&#34;</span><span class=p>,</span> <span class=s2>&#34;Cholesterol&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=n>Path</span><span class=o>.</span><span class=n>cwd</span><span class=p>()</span> <span class=o>/</span> <span class=s2>&#34;heart_processed.csv&#34;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span></code></pre></div><p>Stay tuned for our next post, where we&rsquo;ll dive into selecting and training a model using our freshly preprocessed heart disease data. Exciting insights await ‚ù§Ô∏è !</p></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div id=stickySideBar class=sticky-sidebar><div id=toc-wrapper><aside class=toc></aside></div><aside class=tags><ul class="tags-ul list-unstyled list-inline mb-0 text-center"><li class="list-inline-item m-1"><a href=https://billsioros.github.io/tags/python target=_blank>Python</a></li><li class="list-inline-item m-1"><a href=https://billsioros.github.io/tags/machine-learning target=_blank>Machine Learning</a></li><li class="list-inline-item m-1"><a href=https://billsioros.github.io/tags/data-science target=_blank>Data Science</a></li><li class="list-inline-item m-1"><a href=https://billsioros.github.io/tags/artificial-intelligence target=_blank>Artificial Intelligence</a></li><li class="list-inline-item m-1"><a href=https://billsioros.github.io/tags/exploratory-data-analysis target=_blank>Exploratory Data Analysis</a></li></ul></aside><aside class="social text-center"><div class="social-content mb-0"><ul class="list-inline mb-0"><li class="list-inline-item text-center"><a target=_blank href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fbillsioros.github.io%2fposts%2fexploratory-data-analysis%2f"><i class="fab fa-linkedin"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://twitter.com/share?text=Exploratory%20Data%20Analysis&url=https%3a%2f%2fbillsioros.github.io%2fposts%2fexploratory-data-analysis%2f"><i class="fab fa-twitter"></i></a></li><li class="list-inline-item text-center"><a target=_blank href='mailto:?subject=Exploratory%20Data%20Analysis&amp;body=Check%20out%20this%20site https%3a%2f%2fbillsioros.github.io%2fposts%2fexploratory-data-analysis%2f'><i class="fa fa-envelope"></i></a></li></ul></div></aside><div style=display:flex;flex-direction:row;justify-content:space-between><a href=https://billsioros.github.io/posts/exploratory-data-analysis/ class="article-control nextPost"><span class="text-muted font-weight-light mx-2">Next</span>
<i class="fas fa-angle-right"></i></a></div></div></div></div><div class=row><div class="col-sm-12 col-md-12 col-lg-9 p-4"></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><div class=progress><div id=scroll-progress-bar class=progress-bar role=progressbar aria-valuenow=0 aria-valuemin=0 aria-valuemax=100></div></div><script src=/js/scrollProgressBar.js></script><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}let stickySideBarElem=document.getElementById("stickySideBar"),stickyNavBar=!0;if(stickyNavBar){let e=document.getElementById("profileHeader"),t=e.offsetHeight+15;stickySideBarElem.style.top=t+"px"}else stickySideBarElem.style.top="50px"</script><script src=/js/readingTime.js></script><script>tocbot.init({tocSelector:".toc",contentSelector:".toc-content",headingSelector:"h1, h2, h3",hasInnerContainers:!0})</script></div><footer class="d-flex flex-column justify-content-end" style=flex-grow:1><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center">&copy; 2024 All rights reserved</div></div></div></footer><script src=/bootstrap-5/js/bootstrap.bundle.min.js></script><script>const button_=document.getElementById("theme-toggle");localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?(document.body.classList.remove("dark"),button_.classList.add("light")):window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><script>const button=document.getElementById("theme-toggle");button.addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),button.classList.toggle("light"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),button.classList.toggle("light"),localStorage.setItem("pref-theme","dark"))});var tooltipTriggerList=[].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]')),tooltipList=tooltipTriggerList.map(function(e){return new bootstrap.Tooltip(e)})</script><script src=/js/search.js></script></body></html>